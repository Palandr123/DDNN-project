{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from models import DnCNN\n",
    "from dataset import prepare_data, Dataset_train, Dataset_val\n",
    "from utils import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter\n",
    "noiseL = 25\n",
    "batchSize = 128\n",
    "num_of_layers = 17\n",
    "lr = 1e-3\n",
    "training = 'R2R'\n",
    "alpha = 0.5\n",
    "outf = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print('Loading dataset ...\\n')\n",
    "\n",
    "\n",
    "sigma = noiseL\n",
    "dataset_train = Dataset_train('train_sigma_%d' %sigma)\n",
    "dataset_val = Dataset_val('val_%d_Set68' %sigma)\n",
    "loader_train = DataLoader(dataset=dataset_train, num_workers=4, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "print(\"# of training samples: %d\\n\" % int(len(dataset_train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "net = DnCNN(channels=1, num_of_layers=num_of_layers)\n",
    "net.apply(weights_init_kaiming)\n",
    "criterion = nn.MSELoss(size_average=False)\n",
    "# Move to GPU\n",
    "device_ids = [0]\n",
    "model = nn.DataParallel(net, device_ids=device_ids).cuda()\n",
    "# model = net.to(device)\n",
    "criterion.cuda()\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# training\n",
    "\n",
    "MODEL_PATH = outf+\"/logs/%s_%d/\"%(training,sigma)\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "now = datetime.now()\n",
    "print('Start training.....',now.strftime(\"%H:%M:%S\"))\n",
    "for epoch in range(1):\n",
    " \n",
    "    # train\n",
    "    for i, data in enumerate(loader_train):\n",
    "        # print(data[0].shape)\n",
    "        clean = data[0]\n",
    "        noisy = data[1]\n",
    "\n",
    "\n",
    "        # training step\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        img_train = Variable(noisy.cuda())\n",
    "        clean = Variable(clean.cuda())\n",
    "\n",
    "        eps = sigma/255.\n",
    "        pert = eps*torch.FloatTensor(img_train.size()).normal_(mean=0, std=1.).cuda()\n",
    "        input_train = img_train + alpha*pert\n",
    "        target_train = img_train - pert/alpha\n",
    "\n",
    "        out_train = model(input_train)\n",
    "        loss = criterion(out_train,target_train) / (target_train.size()[0]*2)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # results\n",
    "        model.eval()\n",
    "\n",
    "        out_train = torch.clamp(model(img_train), 0., 1.)\n",
    "\n",
    "        psnr_train = batch_PSNR(out_train, clean, 1.)\n",
    "        print(\"%s [epoch %d][%d/%d] loss: %.4f  PSNR: %.4f\" %\n",
    "            (opt.training,epoch+1, i+1, len(loader_train), loss.item(),psnr_train))\n",
    "\n",
    "    ## the end of each epoch\n",
    "    if (epoch+1) %1==0 or epoch == 0:\n",
    "        model.eval()\n",
    "        # validate\n",
    "        psnr_val = 0\n",
    "        psnr_val_pert = 0\n",
    "        for k in range(len(dataset_val)):\n",
    "            img_val,imgn_val = dataset_val[k]\n",
    "            img_val = torch.unsqueeze(img_val,0)\n",
    "            imgn_val = torch.unsqueeze(imgn_val,0)\n",
    " \n",
    "            img_val, imgn_val = img_val.cuda(), imgn_val.cuda() \n",
    "   \n",
    "            out_val = None\n",
    "            aver_num = 50\n",
    "            eps = opt.val_noiseL/255.\n",
    "            for val_j in range(aver_num):\n",
    "                imgn_val_pert = imgn_val + alpha*eps*torch.FloatTensor(img_val.size()).normal_(mean=0, std=1.).cuda()\n",
    "                with torch.no_grad():\n",
    "                    out_val_single = model(imgn_val_pert)\n",
    "                if out_val  is None:\n",
    "                    out_val= out_val_single.detach()\n",
    "                else:\n",
    "                    out_val += out_val_single.detach()\n",
    "                del out_val_single\n",
    "                \n",
    "            out_val = torch.clamp(out_val/aver_num, 0., 1.)\n",
    "            psnr_val_pert += batch_PSNR(out_val, img_val, 1.)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                out_val = torch.clamp(model(imgn_val),0.,1.)\n",
    "            psnr_val += batch_PSNR(out_val, img_val, 1.)\n",
    "        psnr_val /= len(dataset_val)\n",
    "        psnr_val_pert /= len(dataset_val)\n",
    "        print(\"\\n[epoch %d] PSNR_val: %.4f PNSR_val_pert: %.4f\" % (epoch+1, psnr_val,psnr_val_pert))\n",
    "\n",
    "        \n",
    "   \n",
    "    torch.save(model.state_dict(), os.path.join(MODEL_PATH, 'net.pth'))\n",
    "    now = datetime.now()\n",
    "    print('Total training time.....',now.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
